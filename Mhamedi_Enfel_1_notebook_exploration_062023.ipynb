{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\overflowdata.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Déxouverte de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated(subset=\"Title\").sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des fonctions de nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fonction de nettoyage des balises html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une fonction pour nettoyer le html d'une chaîne\n",
    "def clean_html(string):\n",
    "# Créer un objet BeautifulSoup à partir de la chaîne\n",
    "    soup = BeautifulSoup(string, \"html.parser\")\n",
    "    # Extraire le texte de l'objet BeautifulSoup en ignorant les balises\n",
    "    text = soup.get_text()\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fonction de lemmatization\n",
    "(Tokenizer les phrases, nettoyage des stopwords et caractères spéciaux, lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une fonction pour lemmatiser une phrase\n",
    "def lemmatize_sentence(sentence):\n",
    "\n",
    "    # Tokeniser la phrase en mots\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ['[', ']', ',', '.', ':', '?', '(', ')']\n",
    "\n",
    "    words_w_stopwords = [i for i in words if i not in stopwords]\n",
    "\n",
    "    # Lemmatiser chaque mot et reconstruire la phrase\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatized_words = [wnl.lemmatize(word) for word in words_w_stopwords]\n",
    "    lemmatized_sentence = \" \".join(lemmatized_words)\n",
    "\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Application des fonctions de nettoyage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyage balises html de la colonne Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction clean_html à la colonne Body du dataframe\n",
    "df['Body_cleaned'] = df['Body'].apply(clean_html)\n",
    "\n",
    "# Afficher le résultat\n",
    "df['Body_cleaned']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization de la colonne Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction lemmatize_sentence à la colonne body du dataframe\n",
    "df['Body_lemmatized'] = df['Body_cleaned'].apply(lemmatize_sentence)\n",
    "\n",
    "# Afficher le résultat\n",
    "df['Body_lemmatized']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization de la colonne Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction à la colonne title du dataframe\n",
    "df['Title_lemmatized'] = df['Title'].apply(lemmatize_sentence)\n",
    "\n",
    "# Afficher le résultat\n",
    "df['Title_lemmatized']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyage de la colonne Tags des balises <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tags'] = df['Tags'].str.replace('<', '').str.replace('>', ' ')\n",
    "\n",
    "df['Tags'] = df['Tags'].str.split()\n",
    "\n",
    "# Afficher le résultat\n",
    "print(df['Tags'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition d'un nouveau dataframe avec les deux colonnes Title et Body lemmatizé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher jusqu'à 100 caractères par colonne\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# afficher tout le texte sans tronquer\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Id'] == 1250643,('Tags','Body', 'Body_cleaned', 'Body_lemmatized')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['Title','Id', 'Score', 'ViewCount', 'FavoriteCount', 'AnswerCount', 'Body', 'Body_cleaned'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renommer les colonnes \n",
    "data = data.rename(columns={'Body_lemmatized': 'Body'})\n",
    "data = data.rename(columns={'Title_lemmatized': 'Title'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Représentation des mots de la colonne Title en WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire la colonne des titres\n",
    "titles = data['Title']\n",
    "\n",
    "# Concaténer les titres en une seule chaîne de texte\n",
    "text = \" \".join(title for title in titles)\n",
    "\n",
    "# Créer un objet WordCloud\n",
    "wc = WordCloud(background_color=\"white\", max_words=100)\n",
    "\n",
    "# Générer le nuage de mots à partir du texte\n",
    "wc.generate(text)\n",
    "\n",
    "# Afficher le nuage de mots\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire la colonne des titres\n",
    "titles = data['Body']\n",
    "\n",
    "# Concaténer les titres en une seule chaîne de texte\n",
    "text = \" \".join(title for title in titles)\n",
    "\n",
    "# Créer un objet WordCloud\n",
    "wc = WordCloud(background_color=\"white\", max_words=100)\n",
    "\n",
    "# Générer le nuage de mots à partir du texte\n",
    "wc.generate(text)\n",
    "\n",
    "# Afficher le nuage de mots\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data\\dataframe.csv', encoding='utf-8', index=False, errors='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une instance de CountVectorizer\n",
    "vectorizer = CountVectorizer(lowercase=True,  ngram_range=(1,2), min_df=5, max_df=0.8)\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "vectorizer.fit(df_train['Title'])\n",
    "\n",
    "df_test['quest'] = df_test['Title'] + ' ' + df_test['Body']\n",
    "\n",
    "# Appliquer le transformeur sur la colonne quest\n",
    "counts_test_quest = vectorizer.transform(df_test['quest'])\n",
    "\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "counts = pd.DataFrame(counts_test_quest.toarray(), columns=vocab)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(lowercase=True,  ngram_range=(1,2), min_df=5, max_df=0.8)\n",
    "\n",
    "df_train, df_test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "tf_vectorizer.fit(df_train['Title'])\n",
    "\n",
    "# Créer une nouvelle colonne quest qui concatène Title et Body\n",
    "df_test['quest'] = df_test['Title'] + ' ' + df_test['Body']\n",
    "\n",
    "# Appliquer le transformeur sur la colonne quest\n",
    "tdf_counts= tf_vectorizer.transform(df_test['quest'])\n",
    "\n",
    "tf_vocab = tf_vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les scores tf-idf de chaque mot pour chaque document\n",
    "for i, doc in enumerate(df_test['quest']):\n",
    "    print(f\"Document {i}: {doc}\")\n",
    "\n",
    "for j, word in enumerate(vocab):\n",
    "    if tdf_counts[i,j] > 0:\n",
    "        print(f\"{word}: {tdf_counts[i,j]:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher la taille du dataframe df_test\n",
    "print(df_test.shape)\n",
    "\n",
    "# afficher les premières lignes du dataframe df_test\n",
    "print(df_test.head())\n",
    "\n",
    "# afficher la taille de la matrice tdf_counts\n",
    "print(tdf_counts.shape)\n",
    "\n",
    "# afficher le nombre de valeurs non nulles dans la matrice tdf_counts\n",
    "print(tdf_counts.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
