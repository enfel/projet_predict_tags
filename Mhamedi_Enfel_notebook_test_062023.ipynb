{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "import gensim\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import nltk\n",
    "\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import LdaMulticore, CoherenceModel\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import gensim\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import cluster, metrics\n",
    "\n",
    "from sklearn import manifold, decomposition\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement de données\n",
    "\n",
    "Les données ont été récupéré du site StackOverFlow en intégrant des filtres à la requette SQL (filtres sur le nombre de tags par question, le score ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - APPROCHE NON SUPERVISEE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition des données en données d'entrainement et données test\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une nouvelle colonne qui concatène 'title' et 'body'\n",
    "df['text'] = df['Title'] + ' ' + df['Body']\n",
    "\n",
    "# Diviser le dataframe en train et test avec un ratio de 0.2\n",
    "X_train, X_test = train_test_split(df,  test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réalisation de bag of word en utilisant CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un objet CountVectorizer pour vectoriser les textes\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1,2))\n",
    "\n",
    "# Transformer les textes en une matrice de comptage de mots\n",
    "vect_train = vectorizer.fit_transform(X_train['text'])\n",
    "vect_test = vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle LDA permet d'extraire des topics (ou thèmes) à partir d'un corpus de textes en utilisant un apprentissage non supervisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer un objet Dictionary à partir des mots du vectorizer\n",
    "dictionary = Dictionary.from_corpus(Sparse2Corpus(vect_train, documents_columns=False), id2word=dict((id, word) for word, id in vectorizer.vocabulary_.items()))\n",
    "\n",
    "#Créer un objet Corpus à partir de la matrice vect_train\n",
    "corpus = Sparse2Corpus(vect_train, documents_columns=False)\n",
    "#Transformer le corpus en une liste de listes de mots en utilisant le dictionnaire\n",
    "texts = [[dictionary[word_id] for word_id, freq in doc] for doc in corpus]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Définir l'interval de nombres de topics à tester\n",
    "num_topics_range = range (2, 10)\n",
    "\n",
    "#Créer une liste vide pour stocker les valeur du score 'perplexity'\n",
    "perplexities = []\n",
    "\n",
    "#Boucler sur les nombres de topics\n",
    "for num_topics in num_topics_range:\n",
    "    #Créer un modèle LDA avec le nombre de topics courant\n",
    "    lda_per = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42)\n",
    "    #Calculer la perplexité du modèle sur le corpus de test\n",
    "    perplexity = lda_per.log_perplexity(Sparse2Corpus(vect_test, documents_columns=False))\n",
    "    #Ajouter la perplexité à la liste\n",
    "    perplexities.append(perplexity)\n",
    "    print(f\"perplexity avec {num_topics} topics: {perplexity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tracer un graphique avec les nombres de topics en abscisse et les perplexités en ordonnée\n",
    "plt.figure()\n",
    "plt.plot(num_topics_range, perplexities)\n",
    "plt.xlabel('Nombre topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity du model en fonction de différents nombres de topics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_index = np.argmin(perplexities)\n",
    "\n",
    "#Trouver le nombre de topics correspondant\n",
    "best_num_topics = num_topics_range[best_index]\n",
    "\n",
    "#Afficher le meilleur nombre de topics\n",
    "print(f\"Le meilleur nombre de topics pour le modèle est {best_num_topics}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence score\n",
    "\n",
    "Le coherence score est une mesure qui évalue la cohérence des mots-clés d'un topic en fonction de leur co-occurrence dans les documents. Plus le coherence score est élevé, plus le topic est cohérent et interprétable.\n",
    "\n",
    "Pour calculer le coherence score, il faut utiliser la classe CoherenceModel de gensim et lui passer le modèle LDA, le corpus, le dictionnaire et la méthode de cohérence à utiliser. Il existe plusieurs méthodes de cohérence, mais la plus courante est la méthode 'c_v'.\n",
    "\n",
    "Pour déterminer le nombre de topics optimum, il faut tester plusieurs valeurs de num_topics et comparer les coherence scores correspondants. On va utiliser une boucle for pour créer plusieurs modèles LDA avec différentes valeurs de num_topics et calculer leur coherence score avec la méthode get_coherence() de CoherenceModel. On peut ensuite tracer un graphique qui montre l'évolution du coherence score en fonction du nombre de topics et choisir la valeur qui maximise le coherence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_range = range(3, 17)\n",
    "\n",
    "#réer une liste vide pour stocker les coherence scores\n",
    "coherence_scores = []\n",
    "\n",
    "#Créer une boucle for pour tester chaque valeur de num_topics\n",
    "for num_topics in num_topics_range:\n",
    "\n",
    "    #Créer un objet LDA avec la valeur courante de num_topics\n",
    "    lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, random_state=42)\n",
    "\n",
    "    #Créer un objet CoherenceModel avec la méthode 'c_v'\n",
    "    cm = CoherenceModel(model=lda, corpus=corpus, dictionary=dictionary, coherence='c_v', texts=texts)\n",
    "\n",
    "\n",
    "    #Calculer le coherence score et l'ajouter à la liste\n",
    "    coherence_score = cm.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "\n",
    "    #Afficher le coherence score pour la valeur courante de num_topics\n",
    "    print(f\"Coherence score avec {num_topics} topics: {coherence_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Tracer un graphique qui montre l'évolution du coherence score en fonction du nombre de topics\n",
    "plt.plot(num_topics_range, coherence_scores)\n",
    "plt.xlabel('Nombre topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.title('Coherence score en fonction du nombre de topics')\n",
    "plt.show()\n",
    "\n",
    "#Choisir le nombre de topics optimum qui maximise le coherence score\n",
    "num_topics_opt = num_topics_range[np.argmax(coherence_scores)]\n",
    "print(f\"Le nombre de topic optimum est {num_topics_opt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer un objet LDA avec le nombre de topics optimum\n",
    "lda_opt = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics_opt, random_state=42)\n",
    "\n",
    "#Afficher les mots-clés de chaque topic\n",
    "words = vectorizer.get_feature_names()\n",
    "for i, topic in enumerate(lda_opt.show_topics(formatted=False)):\n",
    "    print(f\"Topic {i+1}:\")\n",
    "    print(\" \".join([word for word, weight in topic[1]]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "#Afficher la distribution des topics pour chaque question\n",
    "topics = lda_opt.get_document_topics((corpus), minimum_probability=0)\n",
    "for i, question in enumerate(X_train['text']):\n",
    "    print(f\"Question {i+1}: {question}\")\n",
    "    print(f\"Topic distribution: {[prob for topic, prob in topics[i]]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_opt = pyLDAvis.gensim_models.prepare(lda_opt, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(data_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_opt = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer un objet LDA avec le nombre de topics optimum\n",
    "lda_opt = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics_opt, random_state=42)\n",
    "\n",
    "#Afficher les mots-clés de chaque topic\n",
    "words = vectorizer.get_feature_names()\n",
    "for i, topic in enumerate(lda_opt.show_topics(formatted=False)):\n",
    "    print(f\"Topic {i+1}:\")\n",
    "    print(\" \".join([word for word, weight in topic[1]]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "#Afficher la distribution des topics pour chaque question\n",
    "topics = lda_opt.get_document_topics((corpus), minimum_probability=0)\n",
    "for i, question in enumerate(X_train['text']):\n",
    "    print(f\"Question {i+1}: {question}\")\n",
    "    print(f\"Topic distribution: {[prob for topic, prob in topics[i]]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_opt = pyLDAvis.gensim_models.prepare(lda_opt, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(data_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_opt = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Créer un objet LDA avec 4 topics \n",
    "lda_opt = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics_opt, random_state=42)\n",
    "\n",
    "#Afficher les mots-clés de chaque topic\n",
    "words = vectorizer.get_feature_names()\n",
    "for i, topic in enumerate(lda_opt.show_topics(formatted=False)):\n",
    "    print(f\"Topic {i+1}:\")\n",
    "    print(\" \".join([word for word, weight in topic[1]]))\n",
    "    print(\"\\n\")\n",
    "\n",
    "#Afficher la distribution des topics pour chaque question\n",
    "topics = lda_opt.get_document_topics((corpus), minimum_probability=0)\n",
    "for i, question in enumerate(X_train['text']):\n",
    "    print(f\"Question {i+1}: {question}\")\n",
    "    print(f\"Topic distribution: {[prob for topic, prob in topics[i]]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des topics et des mots associés (pyLDAVIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_opt = pyLDAvis.gensim_models.prepare(lda_opt, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(data_opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mtopics-words est une matrice qui contient les poids des mots pour chaque topic. Chaque ligne correspond à un topic et chaque colonne correspond à un mot. La valeur à la position (i, j) indique le poids du mot j dans le topic i. Le poids peut être interprété comme la probabilité du mot dans le topic ou comme le score de pertinence du mot pour le topic selon la méthode utilisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenir la matrice Mtopics-words à partir du modèle LDA\n",
    "Mtopics_words = lda_opt.get_topics()\n",
    "#Mtopics_words = np.where(Mtopics_words < 0.05, 0, Mtopics_words)\n",
    "\n",
    "\n",
    "#Créer un dataframe à partir de la matrice Mtopics-words\n",
    "df = pd.DataFrame(Mtopics_words, index=['Topic '+str(i+1) for i in range(num_topics_opt)], columns=vectorizer.get_feature_names())\n",
    "\n",
    "\"\"\"#Tracer la carte de chaleur\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df, cmap='Oranges')\n",
    "plt.title('Mtopics-words matrix')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\n",
    "#Sélectionner 200 colonnes aléatoires du dataframe df\n",
    "df_sample = df.sample(n=50, axis=1)\n",
    "\n",
    "#Tracer la carte de chaleur avec le dataframe échantillonné\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df_sample, cmap='Oranges')\n",
    "plt.title('Mtopics-words matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtopics_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Obtenir la matrice Mtopics-words à partir du modèle LDA\n",
    "Mtopics_words = lda_opt.get_topics()\n",
    "\n",
    "#Obtenir les noms des mots du vocabulaire\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "#Obtenir le nombre de sujets et de mots\n",
    "num_topics = Mtopics_words.shape[0]\n",
    "num_words = Mtopics_words.shape[1]\n",
    "\n",
    "#Créer une figure et un axe\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "#Créer un tableau pour stocker les positions des barres\n",
    "bottom = np.zeros(num_words)\n",
    "\n",
    "#Créer une liste de couleurs\n",
    "colors = plt.cm.Oranges(np.linspace(0.2, 1, num_topics))\n",
    "\n",
    "#Boucler sur les sujets\n",
    "for i in range(num_topics):\n",
    "    #Tracer une barre pour le sujet i avec la couleur i\n",
    "    ax.bar(words, Mtopics_words[i], bottom=bottom, color=colors[i], label='Topic '+str(i+1))\n",
    "    #Mettre à jour les positions des barres\n",
    "    bottom += Mtopics_words[i]\n",
    "\n",
    "#Ajouter un titre et des légendes\n",
    "ax.set_title('Mtopics-words matrix')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "#Afficher le diagramme\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs de la matrice M(train)quest-topics représentent les probabilités pour chaque question d'appartenir à chacun des topics. Plus la valeur est proche de 1, plus la question est fortement liée au topic correspondant. Plus la valeur est proche de 0, plus la question est faiblement liée au topic correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenir la liste des distributions de topics pour chaque question du train\n",
    "topics_train = lda_opt.get_document_topics(corpus)\n",
    "\n",
    "#Obtenir le nombre de questions et de topics\n",
    "num_questions = len(topics_train)\n",
    "num_topics = lda_opt.num_topics\n",
    "\n",
    "#Créer une matrice numpy de zéros avec la forme (num_questions, num_topics)\n",
    "Mtrain_quest_topics = np.zeros((num_questions, num_topics))\n",
    "\n",
    "#Boucler sur les questions\n",
    "for i in range(num_questions):\n",
    "    #Obtenir la distribution de topics pour la question i\n",
    "    topics = topics_train[i]\n",
    "#Boucler sur les tuples (topic_id, probability)\n",
    "for topic_id, probability in topics:\n",
    "    #Remplir la matrice avec la probabilité à l'indice (i, topic_id)\n",
    "    np.put(Mtrain_quest_topics, [i*num_topics + topic_id], probability)\n",
    "\n",
    "#Mtrain_quest_topics = np.where(Mtrain_quest_topics < 0.01, 0, Mtrain_quest_topics)\n",
    "\n",
    "#Afficher la matrice\n",
    "print(Mtrain_quest_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenir le topic dominant pour chaque question\n",
    "topics_dominant = np.argmax(Mtrain_quest_topics, axis=1)\n",
    "\n",
    "#Afficher les topics dominants\n",
    "print(topics_dominant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_opt.show_topic(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_opt.show_topic(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtrain_quest_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtopics_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtrain_quest_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mtopics_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilité des mots pour les questions train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiplier les deux matrices M(train)quest-topics et Mtopics-words\n",
    "#Mtrain_quest_words = np.dot(Mtrain_quest_topics, Mtopics_words)\n",
    "\n",
    "#Afficher la matrice M(train)quest-words\n",
    "#print(Mtrain_quest_words)\n",
    "\n",
    "\n",
    "#Multiplier les deux matrices M(train)quest-topics et Mtopics-words\n",
    "#Mtrain_quest_words = np.dot(Mtrain_quest_topics[:1000, :], Mtopics_words[:, :100])\n",
    "Mtrain_quest_words = np.matmul(Mtrain_quest_topics[:1000, :], Mtopics_words[:, :100])\n",
    "\n",
    "\n",
    "#Afficher la matrice M(train)quest-words\n",
    "print(Mtrain_quest_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilité de mots pour les questions test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir la matrice vect_test en un objet Corpus\n",
    "corpus_test = Sparse2Corpus(vect_test, documents_columns=False)\n",
    "\n",
    "#Obtenir la distribution de topics pour chaque question du test\n",
    "topics_test = lda_opt.get_document_topics(corpus_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(mot | question) = P(mot | topic) * P(topic | question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenir la matrice M(test)quest-topics\n",
    "Mtest_quest_topics = np.zeros((len(topics_test), lda_opt.num_topics))\n",
    "for i in range(len(topics_test)):\n",
    "    topics = topics_test[i]\n",
    "    \n",
    "for topic_id, probability in topics:\n",
    "    np.put(Mtest_quest_topics, [i*lda_opt.num_topics + topic_id], probability)\n",
    "\n",
    "#Obtenir la matrice Mtopics-words\n",
    "Mtopics_words = lda_opt.get_topics()\n",
    "\n",
    "#Multiplier les deux matrices M(test)quest-topics et Mtopics-words\n",
    "Mtest_quest_words = np.dot(Mtest_quest_topics[:1000, :], Mtopics_words[:, :100])\n",
    "\n",
    "\n",
    "#Afficher la matrice M(test)quest-words\n",
    "print(Mtest_quest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "#Afficher la question et la distribution de topics\n",
    "print(f\"Question {i+1}: {X_test['text'].iloc[i]}\")\n",
    "print(f\"Topic distribution: {[prob for topic, prob in topics_test[i]]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code permettra d'obtenir une liste de valeurs de cohérence pour chaque seuil testé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Créer une liste vide pour stocker les valeurs de cohérence\n",
    "coherence_values = []\n",
    "\n",
    "# Faire une boucle for qui teste les seuils entre 0 et 1, avec un pas de 0.01\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "\n",
    "    # Appliquer la fonction np.where aux matrices avec le seuil courant\n",
    "    Mtrain_quest_topics_threshold = np.where(Mtrain_quest_topics < threshold, 0, Mtrain_quest_topics)\n",
    "    Mtopics_words_threshold = np.where(Mtopics_words < threshold, 0, Mtopics_words)\n",
    "\n",
    "    # Créer un modèle de cohérence avec le modèle LDA et les matrices seuillées\n",
    "    #coherence_model_lda = CoherenceModel(model=lda_opt, topics=Mtopics_words_threshold, texts=Mtrain_quest_topics_threshold, coherence='c_v')\n",
    "    coherence_model_lda = CoherenceModel(model=lda_opt, dictionary=dictionary, topics=Mtopics_words_threshold, texts=Mtrain_quest_topics_threshold, coherence='c_v')\n",
    "\n",
    "    # Calculer la cohérence du modèle et l'ajouter à la liste\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    coherence_values.append(coherence_lda)\n",
    "    print(f\"Coherence score avec {threshold} threshold: {coherence_score}\")\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code permettra d'afficher les topics et les mots pour chaque seuil testé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Créer une liste vide pour stocker les topics et les mots\n",
    "topics_words = []\n",
    "\n",
    "# Faire une boucle for qui teste les seuils entre 0 et 1, avec un pas de 0.01\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "\n",
    "# Appliquer la fonction np.where aux matrices avec le seuil courant\n",
    "Mtrain_quest_topics_threshold = np.where(Mtrain_quest_topics < threshold, 0, Mtrain_quest_topics)\n",
    "Mtopics_words_threshold = np.where(Mtopics_words < threshold, 0, Mtopics_words)\n",
    "\n",
    "# Créer un nouveau modèle LDA avec les matrices seuillées\n",
    "lda_model_threshold = LdaModel(Mtrain_quest_topics_threshold, num_topics=10, id2word=Mtopics_words_threshold)\n",
    "\n",
    "# Afficher les topics et les mots avec la fonction show_topic()\n",
    "print(f\"Seuil: {threshold}\")\n",
    "for topic in range(10):\n",
    "print(f\"Topic {topic}: {lda_model_threshold.show_topic(topic)}\")\n",
    "\n",
    "# Ajouter les topics et les mots à la liste\n",
    "topics_words.append(lda_model_threshold.show_topics())\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code permet d'obtenir une matrice de similarité cosinus entre les questions train et test. Chaque élément de la matrice représente la similarité cosinus entre une question train et une question test. La similarité cosinus varie entre -1 et 1, où 1 signifie une similarité maximale, 0 signifie une similarité nulle, et -1 signifie une similarité minimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculer la similarité cosinus entre les matrices\n",
    "similarity_matrix = cosine_similarity(Mtrain_quest_topics, Mtest_quest_topics)\n",
    "\n",
    "# Afficher la matrice de similarité\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un histogramme de la matrice de similarité\n",
    "plt.hist(similarity_matrix.flatten(), bins=20)\n",
    "plt.xlabel(\"Similarité cosinus\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.title(\"La similarité cosinus entre les questions train et test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer une carte de chaleur de la matrice de similarité\n",
    "plt.imshow(similarity_matrix, cmap=\"hot\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Questions test\")\n",
    "plt.ylabel(\"Questions train\")\n",
    "plt.title(\"Carte de chaleur de la similarité cosinus entre les questions train et test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le vectorizer TF-IDF \n",
    "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000)\n",
    "\n",
    "# Transformer les données textuelles en vecteurs TF-IDF\n",
    "vect_train = vectorizer.fit_transform(X_train['text'])\n",
    "\n",
    "# Convertir la matrice TF-IDF en format compatible avec gensim\n",
    "corpus = gensim.matutils.Sparse2Corpus(vect_train, documents_columns=False)\n",
    "\n",
    "# Créer le dictionnaire des mots et de leurs indices \n",
    "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "\n",
    "# Créer le modèle LDA avec gensim\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=10, random_state=100, update_every=1, chunksize=100, passes=10, alpha='auto', per_word_topics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - APPROCHE SUPPERVISEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des modules \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de la target et des features \\ Partition des données en train  test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une nouvelle colonne qui concatène 'title' et 'body'\n",
    "df['text'] = df['Title'] + ' ' + df['Body']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df[\"Tags\"] = df[\"Tags\"].apply(ast.literal_eval)\n",
    "print(df[\"Tags\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultiLabelBinarizer est une classe de sklearn.preprocessing qui permet de transformer des labels multiclasse en une matrice binaire indiquant la présence ou l'absence de chaque classe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition des données en train et test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données en train et test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"Tags\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une liste des 50 tags les plus fréquents\n",
    "top_tags = df[\"Tags\"].explode().value_counts().head(50).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Suppression des répétitions\n",
    "top_tags = []\n",
    "for tg in top_tags0:\n",
    "    top_tags.append([word for word in tg if word in top_tags0])\n",
    "top_tags = np.asarray(top_tags)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un objet MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=top_tags)\n",
    "\n",
    "# Transformer les tags du train set en une matrice binaire\n",
    "y_train_bin = mlb.fit_transform(y_train)\n",
    "\n",
    "# Transformer les tags du test set en une matrice binaire\n",
    "y_test_bin = mlb.transform(y_test)\n",
    "\n",
    "# Créer un objet TfidfVectorizer pour transformer les textes en vecteurs de fréquence\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Transformer les textes du train set en une matrice de fréquence\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transformer les textes du test set en une matrice de fréquence\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"tfidf.get_feature_names_out()\n",
    "df_bow_sklearn = pd.DataFrame(X_train_tfidf.toarray(),columns=vectorizer.get_feature_names())\n",
    "df_bow_sklearn.head()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlb.classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "définition des fonctions communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction des tags/ approche non suppervisés\n",
    "def predict_supervised_tags(n,y_test,y_pred):\n",
    "    for i in range(n):\n",
    "        print(\"Prédit : \", mlb.inverse_transform(y_pred)[i])\n",
    "        print(\"Valeur réelle : \", mlb.inverse_transform(y_test)[i])\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction des tags en entrainant le modèle LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneVsRestClassifier est une classe de scikit-learn qui permet de gérer le cas où la cible est multilabel, c'est-à-dire qu'un document peut avoir plusieurs étiquettes. OneVsRestClassifier utilise un estimateur binaire (par exemple LogisticRegression) pour entraîner un classificateur par étiquette, et combine les résultats pour prédire les étiquettes d'un document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un objet OneVsRestClassifier avec LogisticRegression \n",
    "ovr_logreg = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Entraîner les classificateurs sur le train set\n",
    "ovr_logreg.fit(X_train_tfidf, y_train_bin)\n",
    "\n",
    "# Prédire les tags sur le test set\n",
    "y_pred_logreg = ovr_logreg.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_supervised_tags(10, y_test_bin, y_pred_logreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction des tags en entrainant le modèle SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_sgd = OneVsRestClassifier(SGDClassifier())\n",
    "\n",
    "ovr_sgd.fit(X_train_tfidf, y_train_bin)\n",
    "\n",
    "y_pred_sgd = ovr_sgd.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_supervised_tags(10, y_test_bin, y_pred_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Enregistrer le modèle dans un fichier\n",
    "filename = \"ovr_sgd.pickle\"\n",
    "pickle.dump(ovr_sgd, open(filename, \"wb\"))\n",
    "\n",
    "# Charger le modèle à partir du fichier\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# Faire des prédictions avec le modèle chargé\n",
    "y_pred_sgd = loaded_model.predict(X_test_tfidf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jaccard_score est une mesure de la similarité entre deux ensembles d'étiquettes. Il est défini comme la taille de l'intersection divisée par la taille de l'union de deux ensembles d'étiquetteshttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html. Il peut être utilisé pour comparer l'ensemble des étiquettes prédites pour un échantillon à l'ensemble des étiquettes réelles. Plus le jaccard_score est proche de 1, plus les deux ensembles sont similaires. Plus il est proche de 0, plus ils sont différentshttps://www.statology.org/jaccard-similarity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Calculer du jaccard_score \n",
    "jac_score_logreg = jaccard_score(y_test_bin, y_pred_logreg, average='micro')\n",
    "jac_score_sgd = jaccard_score(y_test_bin, y_pred_sgd, average='micro')\n",
    "\n",
    "# Calcul du precision score\n",
    "pres_score_logreg = precision_score(y_test_bin,y_pred_logreg, average = \"macro\")\n",
    "pres_score_sgd = precision_score(y_test_bin,y_pred_sgd, average = \"macro\")\n",
    "\n",
    "# Calcul de l'accuracy score\n",
    "accuracy_logreg = accuracy_score(y_test_bin, y_pred_logreg)\n",
    "accuracy_sgd = accuracy_score(y_test_bin, y_pred_sgd)\n",
    "\n",
    "# Comparer les scores\n",
    "print (\"Jaccard score : \")\n",
    "print(\"Jaccard score pour LogisticRegression:\", jac_score_logreg)\n",
    "print(\"Jaccard score pour SGDClassifier:\", jac_score_sgd)\n",
    "print (\"\\n\")\n",
    "\n",
    "print (\"Precision score : \")\n",
    "print(\"Precision score pour LogisticRegression:\", pres_score_logreg )\n",
    "print(\"Precision score pour SGDClassifier:\", pres_score_sgd )\n",
    "print (\"\\n\")\n",
    "\n",
    "print (\"Accuracy score : \")\n",
    "print(f\"Accuracy LogisticRegression: {accuracy_logreg:.2f}\")\n",
    "print(f\"Accuracy SGDClassifier: {accuracy_sgd:.2f}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 -  Sentence Embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\dataframe.csv')\n",
    "# Créer une nouvelle colonne qui concatène 'title' et 'body'\n",
    "df = df.dropna()\n",
    "df['text'] = df['Title'] + ' ' + df['Body']\n",
    "# Séparer les données en train et test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"Tags\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "NombreDeTags = 100\n",
    "tags = [t[1:len(t) - 1].split('><') for t in df['Tags']]\n",
    "words = []\n",
    "for t in tags:\n",
    "     words += t\n",
    "\n",
    "freq_totale = Counter(words)\n",
    "mostcommon = np.array(freq_totale.most_common(NombreDeTags))\n",
    "\n",
    "\n",
    "#removing the common words from tags\n",
    "final_tags = []\n",
    "for ts in tags:\n",
    "    final_tags.append([word for word in ts if word in mostcommon])\n",
    "final_tags = np.asarray(final_tags)\n",
    "n = len(max(final_tags, key=len))\n",
    "liste_2 = [x + [None]*(n-len(x)) for x in final_tags]\n",
    "a = np.array(liste_2)\n",
    "final_tags = pd.DataFrame(final_tags, dtype = object)\n",
    "ftags = pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ftags.iloc[:,0]\n",
    "\n",
    "l_cat = list(set(y))\n",
    "y_cat_num = [(l_cat.index(ftags.iloc[i,0])) for i in range(len(ftags))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"catégories : \", l_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul Tsne, détermination des clusters et calcul ARI entre vrais catégorie et n° de clusters\n",
    "def ARI_fct(features) :\n",
    "    time1 = time.time()\n",
    "    num_labels=len(l_cat)\n",
    "    tsne = manifold.TSNE(n_components=2, perplexity=30, n_iter=2000, \n",
    "                                 init='random', learning_rate=200, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(features)\n",
    "    \n",
    "    # Détermination des clusters à partir des données après Tsne \n",
    "    cls = cluster.KMeans(n_clusters=num_labels, n_init=100, random_state=42)\n",
    "    cls.fit(X_tsne)\n",
    "    ARI = np.round(metrics.adjusted_rand_score(y_cat_num, cls.labels_),4)\n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"ARI : \", ARI, \"time : \", time2)\n",
    "    \n",
    "    return ARI, X_tsne, cls.labels_\n",
    "\n",
    "# visualisation du Tsne selon les vraies catégories et selon les clusters\n",
    "def TSNE_visu_fct(X_tsne, y_cat_num, labels, ARI) :\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    \n",
    "    ax = fig.add_subplot(121)\n",
    "    scatter = ax.scatter(X_tsne[:,0],X_tsne[:,1], c=y_cat_num, cmap='Set1')\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=l_cat, loc=\"best\", title=\"Categorie\")\n",
    "    plt.title('Représentation des questions par thèmes réelles')\n",
    "    \n",
    "    ax = fig.add_subplot(122)\n",
    "    scatter = ax.scatter(X_tsne[:,0],X_tsne[:,1], c=labels, cmap='Set1')\n",
    "    ax.legend(handles=scatter.legend_elements()[0], labels=set(labels), loc=\"best\", title=\"Clusters\")\n",
    "    plt.title('Représentation des questions par clusters')\n",
    "    \n",
    "    plt.show()\n",
    "    print(\"ARI : \", ARI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Bert\n",
    "import os\n",
    "import transformers\n",
    "from transformers import *\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de préparation des sentences\n",
    "def bert_inp_fct(sentences, bert_tokenizer, max_length) :\n",
    "    input_ids=[]\n",
    "    token_type_ids = []\n",
    "    attention_mask=[]\n",
    "    bert_inp_tot = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
    "                                              add_special_tokens = True,\n",
    "                                              max_length = max_length,\n",
    "                                              padding='max_length',\n",
    "                                              return_attention_mask = True, \n",
    "                                              return_token_type_ids=True,\n",
    "                                              truncation=True,\n",
    "                                              return_tensors=\"tf\")\n",
    "    \n",
    "        input_ids.append(bert_inp['input_ids'][0])\n",
    "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
    "        attention_mask.append(bert_inp['attention_mask'][0])\n",
    "        bert_inp_tot.append((bert_inp['input_ids'][0], \n",
    "                             bert_inp['token_type_ids'][0], \n",
    "                             bert_inp['attention_mask'][0]))\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    token_type_ids = np.asarray(token_type_ids)\n",
    "    attention_mask = np.array(attention_mask)\n",
    "    \n",
    "    return input_ids, token_type_ids, attention_mask, bert_inp_tot\n",
    "    \n",
    "\n",
    "# Fonction de création des features\n",
    "def feature_BERT_fct(model, model_type, sentences, max_length, b_size, mode='HF') :\n",
    "    batch_size = b_size\n",
    "    batch_size_pred = b_size\n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    time1 = time.time()\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(sentences[idx:idx+batch_size], \n",
    "                                                                      bert_tokenizer, max_length)\n",
    "        \n",
    "        if mode=='HF' :    # Bert HuggingFace\n",
    "            outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "        if mode=='TFhub' : # Bert Tensorflow Hub\n",
    "            text_preprocessed = {\"input_word_ids\" : input_ids, \n",
    "                                 \"input_mask\" : attention_mask, \n",
    "                                 \"input_type_ids\" : token_type_ids}\n",
    "            outputs = model(text_preprocessed)\n",
    "            last_hidden_states = outputs['sequence_output']\n",
    "             \n",
    "        if step ==0 :\n",
    "            last_hidden_states_tot = last_hidden_states\n",
    "            last_hidden_states_tot_0 = last_hidden_states\n",
    "        else :\n",
    "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot,last_hidden_states))\n",
    "    \n",
    "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
    "    \n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"temps traitement : \", time2)\n",
    "     \n",
    "    return features_bert, last_hidden_states_tot\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64\n",
    "batch_size = 8\n",
    "model_type = 'bert-base-uncased'\n",
    "model = TFAutoModel.from_pretrained(model_type)\n",
    "sentences = df['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des features\n",
    "\n",
    "#features_bert, last_hidden_states_tot = feature_BERT_fct(model, model_type, sentences, \n",
    "#                                                         max_length, batch_size, mode='HF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARI, X_tsne, labels = ARI_fct(features_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSNE_visu_fct(X_tsne, y_cat_num, labels, ARI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session () "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_fct(sentence) :\n",
    "    # print(sentence)\n",
    "    sentence_clean = sentence.replace('-', ' ').replace('+', ' ').replace('/', ' ').replace('#', ' ')\n",
    "    word_tokens = word_tokenize(sentence_clean)\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_size=100\n",
    "w2v_window=5\n",
    "w2v_min_count=1\n",
    "w2v_epochs=100\n",
    "maxlen = 24 # adapt to length of sentences\n",
    "sentences = df['text'].to_list()\n",
    "sentences = [gensim.utils.simple_preprocess(text) for text in sentences]\n",
    "\n",
    "# Création et entraînement du modèle Word2Vec\n",
    "\n",
    "print(\"Build & train Word2Vec model ...\")\n",
    "w2v_model = gensim.models.Word2Vec(min_count=w2v_min_count, window=w2v_window,\n",
    "                                                vector_size=w2v_size,\n",
    "                                                seed=42,\n",
    "                                                workers=1)\n",
    "#                                                workers=multiprocessing.cpu_count())\n",
    "\n",
    "w2v_model.build_vocab(sentences)\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=w2v_epochs)\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des sentences (tokenization)\n",
    "\n",
    "print(\"Fit Tokenizer ...\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "x_sentences = pad_sequences(tokenizer.texts_to_sequences(sentences),\n",
    "                                                     maxlen=maxlen,\n",
    "                                                     padding='post') \n",
    "                                                   \n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(\"Number of unique words: %i\" % num_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice d'embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice d'embedding est une matrice qui contient les vecteurs représentant les mots d'un vocabulaire. Chaque ligne de la matrice correspond à un mot et chaque colonne correspond à une dimension du vecteur. La matrice d'embedding permet de transformer un mot en un vecteur de nombres réels qui capture son sens, son contexte et sa similarité avec d'autres mots. La matrice d'embedding peut être apprise à partir de données textuelles à l'aide de méthodes comme Word2Vec ou BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la matrice d'embedding\n",
    "\n",
    "print(\"Create Embedding matrix ...\")\n",
    "w2v_size = 100\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
    "i=0\n",
    "j=0\n",
    "    \n",
    "for word, idx in word_index.items():\n",
    "    i +=1\n",
    "    if word in w2v_words:\n",
    "        j +=1\n",
    "        embedding_vector = model_vectors[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[idx] = model_vectors[word]\n",
    "            \n",
    "word_rate = np.round(j/i,4)\n",
    "print(\"Word embedding rate : \", word_rate)\n",
    "print(\"Embedding matrix: %s\" % str(embedding_matrix.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "\n",
    "input=Input(shape=(len(x_sentences),maxlen),dtype='float64')\n",
    "word_input=Input(shape=(maxlen,),dtype='float64')  \n",
    "word_embedding=Embedding(input_dim=vocab_size,\n",
    "                         output_dim=w2v_size,\n",
    "                         weights = [embedding_matrix],\n",
    "                         input_length=maxlen)(word_input)\n",
    "word_vec=GlobalAveragePooling1D()(word_embedding)  \n",
    "embed_model = Model([word_input],word_vec)\n",
    "\n",
    "embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed_model.predict(x_sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, labels, ARI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session () "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### USE (Universal Sentence Encoder) \n",
    " \n",
    " est un modèle qui encode les phrases dans un espace vectoriel de basse dimension, en utilisant un réseau neuronal profond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import transformers\n",
    "from transformers import *\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle USE\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_USE_fct(sentences, b_size) :\n",
    "    batch_size = b_size\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        feat = embed(sentences[idx:idx+batch_size])\n",
    "\n",
    "        if step ==0 :\n",
    "            features = feat\n",
    "        else :\n",
    "            features = np.concatenate((features,feat))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 31\n",
    "sentences = df['text'].to_list()\n",
    "features_USE = feature_USE_fct(sentences, batch_size)\n",
    "len(features_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARI, X_tsne, labels = ARI_fct(features_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_USE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_visu_fct(X_tsne, y_cat_num, labels, ARI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "embed_model.save(\"embed_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle\n",
    "loaded_model = tf.keras.models.load_model(\"embed_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.keras.save_model(model, \"models/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.pyfunc.load_model(\"models/model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
